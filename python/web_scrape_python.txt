
Trying web scarping with Python, Selenium

Ref1: https://www.edureka.co/blog/web-scraping-with-python/
Ref2: https://oxylabs.io/blog/python-web-scraping
Ref3: https://towardsdatascience.com/web-scraping-using-selenium-python-8a60f4cf40ab

Using Pyhton installed on Windows laptop

1. Check where python is installed on laptop
	>>> import os
	>>> import sys
	>>> os.path.dirname(sys.executable)

2. >>> from selenium import webdriver
	If this is giving an error, use pip to install selenium

	- Locate where Python is installed on Windows
	- From Command propt, go to that location
	- Go to Scripts/ directory where Python is installed
	- pip install selenium

3. >>> driver = webdriver.Chrome(executable_path='c:\path\to\windows\webdriver\executable.exe')

	Open Chrome browser in your laptop and check the version,
    i had version 91 running on my laptop
	
	Go to https://chromedriver.chromium.org/downloads to download version 91

   >>> driver = webdriver.Chrome(executable_path='C:\\Users\id\\Downloads\\chromerdriver.exe')

	This was causing some pop up to come and i am seeing an error, i had to use options
	options = webdriver.ChromeOptions()
	options.add_experimental_option('excludeSwitches', ['enable-logging'])
	driver = webdriver.Chrome(executable_path='<path-to-chrome>', options=options)

    Refer: https://stackoverflow.com/questions/47392423/python-selenium-devtools-listening-on-ws-127-0-0-1

4. >>> driver.get("https://forums.edmunds.com/discussion/62700/acura/rdx/2021-acura-rdx-lease-deals-and-prices")


	ids = driver.find_elements_by_xpath("//*[contains(@id,'Comment_')]")
	comment_ids = []
	for i in ids:
		comment_ids.append(i.get_attribute('id'))
	

	for x in comment_ids:
	    #Extract dates from for each user on a page
	    user_date = driver.find_elements_by_xpath('//*[@id="' + x +'"]/div/div[2]/div[2]/span[1]/a/time')[0]
		date = user_date.get_attribute('title')

	    #Extract user ids from each user on a page
	    userid_element = driver.find_elements_by_xpath('//*[@id="' + x +'"]/div/div[2]/div[1]/span[1]/a[2]')[0]
	    userid = userid_element.text

	    #Extract Message for each user on a page
	    user_message = driver.find_elements_by_xpath('//*[@id="' + x +'"]/div/div[3]/div/div[1]')[0]
	    comment = user_message.text

		print(comment)

5. This is printing all the comments in the edmunds web page

